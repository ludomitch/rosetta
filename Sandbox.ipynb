{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import csv\n",
    "import string\n",
    "from textblob_de import TextBlobDE as TBD\n",
    "from textblob import TextBlob as TBE\n",
    "import spacy\n",
    "import language_check\n",
    "from scipy.spatial.distance import cdist\n",
    "from laserembeddings import Laser\n",
    "import kiwi\n",
    "import utils\n",
    "\n",
    "# Load pre-trained nlp models\n",
    "sp_en = spacy.load(\"en\")\n",
    "sp_de = spacy.load(\"de\")\n",
    "en_checker = language_check.LanguageTool('en-GB')\n",
    "ge_checker = language_check.LanguageTool('de-DE')\n",
    "\n",
    "# Utils\n",
    "def pos_parser(x,y):\n",
    "    blacklist = ['.']\n",
    "    x = [i.tag_ for i in x]\n",
    "    x = {k:x.count(k) for k in x if k not in blacklist}\n",
    "    y = [i.tag_ for i in y]\n",
    "    y = {k:y.count(k) for k in y if k not in blacklist}\n",
    "    if len(x)>len(y):\n",
    "        it = x\n",
    "        nit = y\n",
    "    else:\n",
    "        it = y\n",
    "        nit = x\n",
    "    res = 0\n",
    "    for pos in it:\n",
    "        if pos in nit:\n",
    "            res += abs(it[pos]-nit[[pos]])\n",
    "        else:\n",
    "            res += it[pos]\n",
    "    return res\n",
    "def spacy_parser(x,y, mode='pos_'):\n",
    "    # Models don't have the same entities\n",
    "    whitelist = ['PER', 'PERSON', 'LOC', 'ORG']\n",
    "    if mode in ['ents']:\n",
    "        mode = 'label_'\n",
    "        x = x.ents\n",
    "        y = y.ents\n",
    "    x = [getattr(i,mode) for i in x]\n",
    "    x = {k:x.count(k) for k in x if k}\n",
    "    y = [getattr(i, mode) for i in y]\n",
    "    y = {k:y.count(k) for k in y if k}\n",
    "    if mode in ['label_']:\n",
    "        if 'PERSON' in x:\n",
    "            x['PER'] = x.pop('PERSON')\n",
    "        x = {k:v for k,v in x.items() if k in whitelist}\n",
    "        y = {k:v for k,v in y.items() if k in whitelist}\n",
    "\n",
    "    if len(x)>len(y):\n",
    "        it = x\n",
    "        nit = y\n",
    "    else:\n",
    "        it = y\n",
    "        nit = x\n",
    "    res = 0\n",
    "    for pos in it:\n",
    "        if pos in nit:\n",
    "            res += abs(it[pos]-nit[pos])\n",
    "        else:\n",
    "            res += it[pos]\n",
    "    return res\n",
    "\n",
    "src = pd.read_csv('en-de/train.ende.src', sep=\"\\n\", error_bad_lines=False, quoting=csv.QUOTE_NONE, header=None)\n",
    "target = pd.read_csv('en-de/train.ende.mt', sep=\"\\n\", error_bad_lines=False,quoting=csv.QUOTE_NONE, header=None)\n",
    "scores = pd.read_csv('en-de/train.ende.scores', sep=\"\\n\", error_bad_lines=False,quoting=csv.QUOTE_NONE, header=None)\n",
    "df = src.rename(columns={0:'src'})\n",
    "df['tgt'] = target\n",
    "# df = df.head(10)\n",
    "# Remove punctuation\n",
    "df[['src_p', 'tgt_p']] = df[['src', 'tgt']].applymap(lambda x: x.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "# df['scores'] = scores\n",
    "df['src_len'] = df['src_p'].apply(lambda x: len(x.split(' ')))\n",
    "df['tgt_len'] = df['tgt_p'].apply(lambda x: len(x.split(' ')))\n",
    "df1 = pd.DataFrame({'src':[], 'tgt':[]}).transpose()\n",
    "df1['avg_tkn_len'] = df[['src_len', 'tgt_len']].mean().tolist()\n",
    "count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n",
    "df['src_#punc'] = df['src'].apply(lambda x: count(x,set(string.punctuation)) )\n",
    "df['tgt_#punc'] = df['tgt'].apply(lambda x: count(x,set(string.punctuation)) )\n",
    "df['tgt_polar'] = df['tgt'].apply(lambda x: TBD(x).sentiment.polarity)\n",
    "df['src_polar'] = df['src'].apply(lambda x: TBE(x).sentiment.polarity)\n",
    "df['polar_dff'] = (df['tgt_polar']-df['src_polar']).abs()\n",
    "df['src_sp'] = df['src'].apply(lambda x: sp_en(x))\n",
    "df['tgt_sp'] = df['tgt'].apply(lambda x: sp_de(x))\n",
    "df['src_gram_err'] = df['src'].apply(lambda x: en_checker.check(x))\n",
    "df['tgt_gram_err'] = df['tgt'].apply(lambda x: ge_checker.check(x))\n",
    "df['sp_pos_diff'] = [spacy_parser(x,y, 'pos_') for x,y in zip(df['src_sp'], df['tgt_sp'])]\n",
    "df['sp_ent_diff'] = [spacy_parser(x,y, 'ents') for x,y in zip(df['src_sp'], df['tgt_sp'])]\n",
    "# Laser embeddings\n",
    "x = laser.embed_sentences(df['src'].tolist(), lang='en')\n",
    "y = laser.embed_sentences(df['tgt'].tolist(), lang='de')\n",
    "df['src_laser_embed'] = x.tolist()\n",
    "df['tgt_laser_embed'] = y.tolist()\n",
    "# Laser cosine distance\n",
    "for i in df.index:\n",
    "    df.loc[i, 'laser_embed_cdist'] = cdist(\n",
    "        np.array(df.loc[i, 'src_laser_embed']).reshape(1,-1),\n",
    "        np.array(df.loc[i, 'tgt_laser_embed']).reshape(1,-1),\n",
    "        'cosine')[0][0]\n",
    "# Openkiwi\n",
    "OK_url = 'https://github.com/unbabel/KiwiCutter/releases/download/v1.0/estimator_en_de.torch.zip'\n",
    "utils.download_kiwi(OK_url)\n",
    "model = kiwi.load_model('trained_models/estimator_en_de.torch/estimator_en_de.torch')\n",
    "examples = {'source': df['src'].tolist(),'target': df['tgt'].tolist()}\n",
    "predictions = model.predict(examples)\n",
    "df['openkiwi_score'] = predictions['sentence_scores']\n",
    "\n",
    "df['scores'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "xlmr = torch.hub.load('pytorch/fairseq', 'xlmr.large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('df.pkl')\n",
    "# dist = cdist(x,y, 'cosine')\n",
    "\n",
    "# for i in df.index:\n",
    "#     df.loc[i, 'src_laser_embed'] = x[i]\n",
    "# x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    df.loc[i, 'laser_embed_cdist'] = cdist(\n",
    "        np.array(df.loc[i, 'src_laser_embed']).reshape(1,-1),\n",
    "        np.array(df.loc[i, 'tgt_laser_embed']).reshape(1,-1),\n",
    "        'cosine')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abs_laser_embed_cdist'] = df['laser_embed_cdist'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('df.pkl')\n",
    "# x = np.array(xlmr.encode('banana').tolist()).reshape(1,-1)\n",
    "# y = np.array(xlmr.encode('vegetable').tolist()).reshape(1,-1)\n",
    "# print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from laserembeddings import Laser\n",
    "laser = Laser()\n",
    "embeddings = laser.embed_sentences(\n",
    "    ['apple', 'l√©gume'],\n",
    "    lang=['en', 'fr'])\n",
    "# cdist(x, y, 'cosine')\n",
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ludo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Getting filename\n",
      "Checking if file already downloaded\n",
      "Downloading\n",
      "estimator_en_de.torch.zip: 360MB [01:40, 3.57MB/s]                               \n",
      "Download has finished.\n",
      "Extracting trained_models/estimator_en_de.torch.zip\n",
      "Done extracting\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdist(embeddings[0].reshape(1,-1), embeddings[1].reshape(1,-1))\n",
    "# embeddings = laser.embed_sentences(\n",
    "#     ['let your neural network be polyglot',\n",
    "#      'use multilingual embeddings!'],\n",
    "#     lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_len</th>\n",
       "      <th>tgt_len</th>\n",
       "      <th>src_#punc</th>\n",
       "      <th>tgt_#punc</th>\n",
       "      <th>tgt_polar</th>\n",
       "      <th>src_polar</th>\n",
       "      <th>sp_pos_diff</th>\n",
       "      <th>sp_ent_diff</th>\n",
       "      <th>scores</th>\n",
       "      <th>laser_embed_cdist</th>\n",
       "      <th>abs_laser_embed_cdist</th>\n",
       "      <th>polar_dff</th>\n",
       "      <th>openkiwi_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>src_len</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930897</td>\n",
       "      <td>0.251329</td>\n",
       "      <td>0.282172</td>\n",
       "      <td>0.015372</td>\n",
       "      <td>0.034175</td>\n",
       "      <td>0.470674</td>\n",
       "      <td>0.234507</td>\n",
       "      <td>-0.048007</td>\n",
       "      <td>-0.163272</td>\n",
       "      <td>-0.163272</td>\n",
       "      <td>0.126230</td>\n",
       "      <td>0.156970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tgt_len</th>\n",
       "      <td>0.930897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.261039</td>\n",
       "      <td>0.301643</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>-0.045259</td>\n",
       "      <td>-0.177125</td>\n",
       "      <td>-0.177125</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>0.225158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_#punc</th>\n",
       "      <td>0.251329</td>\n",
       "      <td>0.261039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836125</td>\n",
       "      <td>-0.020326</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.229136</td>\n",
       "      <td>0.216247</td>\n",
       "      <td>-0.019488</td>\n",
       "      <td>-0.192414</td>\n",
       "      <td>-0.192414</td>\n",
       "      <td>-0.008147</td>\n",
       "      <td>0.112684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tgt_#punc</th>\n",
       "      <td>0.282172</td>\n",
       "      <td>0.301643</td>\n",
       "      <td>0.836125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014515</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.253750</td>\n",
       "      <td>0.186801</td>\n",
       "      <td>-0.026848</td>\n",
       "      <td>-0.196261</td>\n",
       "      <td>-0.196261</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.133771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tgt_polar</th>\n",
       "      <td>0.015372</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>-0.020326</td>\n",
       "      <td>-0.014515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213635</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>-0.010209</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>-0.091737</td>\n",
       "      <td>-0.023598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_polar</th>\n",
       "      <td>0.034175</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.213635</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>0.028852</td>\n",
       "      <td>-0.004833</td>\n",
       "      <td>-0.004833</td>\n",
       "      <td>0.129515</td>\n",
       "      <td>-0.002234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp_pos_diff</th>\n",
       "      <td>0.470674</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.229136</td>\n",
       "      <td>0.253750</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180311</td>\n",
       "      <td>-0.034278</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>0.043962</td>\n",
       "      <td>0.203629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp_ent_diff</th>\n",
       "      <td>0.234507</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>0.216247</td>\n",
       "      <td>0.186801</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>0.180311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014452</td>\n",
       "      <td>-0.192739</td>\n",
       "      <td>-0.192739</td>\n",
       "      <td>-0.034608</td>\n",
       "      <td>0.084963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores</th>\n",
       "      <td>-0.048007</td>\n",
       "      <td>-0.045259</td>\n",
       "      <td>-0.019488</td>\n",
       "      <td>-0.026848</td>\n",
       "      <td>-0.010209</td>\n",
       "      <td>0.028852</td>\n",
       "      <td>-0.034278</td>\n",
       "      <td>-0.014452</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054626</td>\n",
       "      <td>-0.054626</td>\n",
       "      <td>-0.021223</td>\n",
       "      <td>-0.022113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laser_embed_cdist</th>\n",
       "      <td>-0.163272</td>\n",
       "      <td>-0.177125</td>\n",
       "      <td>-0.192414</td>\n",
       "      <td>-0.196261</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>-0.004833</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>-0.192739</td>\n",
       "      <td>-0.054626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045329</td>\n",
       "      <td>-0.015807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_laser_embed_cdist</th>\n",
       "      <td>-0.163272</td>\n",
       "      <td>-0.177125</td>\n",
       "      <td>-0.192414</td>\n",
       "      <td>-0.196261</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>-0.004833</td>\n",
       "      <td>-0.074396</td>\n",
       "      <td>-0.192739</td>\n",
       "      <td>-0.054626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045329</td>\n",
       "      <td>-0.015807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polar_dff</th>\n",
       "      <td>0.126230</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>-0.008147</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>-0.091737</td>\n",
       "      <td>0.129515</td>\n",
       "      <td>0.043962</td>\n",
       "      <td>-0.034608</td>\n",
       "      <td>-0.021223</td>\n",
       "      <td>0.045329</td>\n",
       "      <td>0.045329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openkiwi_score</th>\n",
       "      <td>0.156970</td>\n",
       "      <td>0.225158</td>\n",
       "      <td>0.112684</td>\n",
       "      <td>0.133771</td>\n",
       "      <td>-0.023598</td>\n",
       "      <td>-0.002234</td>\n",
       "      <td>0.203629</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>-0.022113</td>\n",
       "      <td>-0.015807</td>\n",
       "      <td>-0.015807</td>\n",
       "      <td>0.050648</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        src_len   tgt_len  src_#punc  tgt_#punc  tgt_polar  \\\n",
       "src_len                1.000000  0.930897   0.251329   0.282172   0.015372   \n",
       "tgt_len                0.930897  1.000000   0.261039   0.301643   0.000708   \n",
       "src_#punc              0.251329  0.261039   1.000000   0.836125  -0.020326   \n",
       "tgt_#punc              0.282172  0.301643   0.836125   1.000000  -0.014515   \n",
       "tgt_polar              0.015372  0.000708  -0.020326  -0.014515   1.000000   \n",
       "src_polar              0.034175  0.021773   0.005937   0.001927   0.213635   \n",
       "sp_pos_diff            0.470674  0.497385   0.229136   0.253750   0.026687   \n",
       "sp_ent_diff            0.234507  0.233480   0.216247   0.186801   0.012901   \n",
       "scores                -0.048007 -0.045259  -0.019488  -0.026848  -0.010209   \n",
       "laser_embed_cdist     -0.163272 -0.177125  -0.192414  -0.196261   0.004593   \n",
       "abs_laser_embed_cdist -0.163272 -0.177125  -0.192414  -0.196261   0.004593   \n",
       "polar_dff              0.126230  0.145774  -0.008147   0.004103  -0.091737   \n",
       "openkiwi_score         0.156970  0.225158   0.112684   0.133771  -0.023598   \n",
       "\n",
       "                       src_polar  sp_pos_diff  sp_ent_diff    scores  \\\n",
       "src_len                 0.034175     0.470674     0.234507 -0.048007   \n",
       "tgt_len                 0.021773     0.497385     0.233480 -0.045259   \n",
       "src_#punc               0.005937     0.229136     0.216247 -0.019488   \n",
       "tgt_#punc               0.001927     0.253750     0.186801 -0.026848   \n",
       "tgt_polar               0.213635     0.026687     0.012901 -0.010209   \n",
       "src_polar               1.000000     0.033873    -0.008617  0.028852   \n",
       "sp_pos_diff             0.033873     1.000000     0.180311 -0.034278   \n",
       "sp_ent_diff            -0.008617     0.180311     1.000000 -0.014452   \n",
       "scores                  0.028852    -0.034278    -0.014452  1.000000   \n",
       "laser_embed_cdist      -0.004833    -0.074396    -0.192739 -0.054626   \n",
       "abs_laser_embed_cdist  -0.004833    -0.074396    -0.192739 -0.054626   \n",
       "polar_dff               0.129515     0.043962    -0.034608 -0.021223   \n",
       "openkiwi_score         -0.002234     0.203629     0.084963 -0.022113   \n",
       "\n",
       "                       laser_embed_cdist  abs_laser_embed_cdist  polar_dff  \\\n",
       "src_len                        -0.163272              -0.163272   0.126230   \n",
       "tgt_len                        -0.177125              -0.177125   0.145774   \n",
       "src_#punc                      -0.192414              -0.192414  -0.008147   \n",
       "tgt_#punc                      -0.196261              -0.196261   0.004103   \n",
       "tgt_polar                       0.004593               0.004593  -0.091737   \n",
       "src_polar                      -0.004833              -0.004833   0.129515   \n",
       "sp_pos_diff                    -0.074396              -0.074396   0.043962   \n",
       "sp_ent_diff                    -0.192739              -0.192739  -0.034608   \n",
       "scores                         -0.054626              -0.054626  -0.021223   \n",
       "laser_embed_cdist               1.000000               1.000000   0.045329   \n",
       "abs_laser_embed_cdist           1.000000               1.000000   0.045329   \n",
       "polar_dff                       0.045329               0.045329   1.000000   \n",
       "openkiwi_score                 -0.015807              -0.015807   0.050648   \n",
       "\n",
       "                       openkiwi_score  \n",
       "src_len                      0.156970  \n",
       "tgt_len                      0.225158  \n",
       "src_#punc                    0.112684  \n",
       "tgt_#punc                    0.133771  \n",
       "tgt_polar                   -0.023598  \n",
       "src_polar                   -0.002234  \n",
       "sp_pos_diff                  0.203629  \n",
       "sp_ent_diff                  0.084963  \n",
       "scores                      -0.022113  \n",
       "laser_embed_cdist           -0.015807  \n",
       "abs_laser_embed_cdist       -0.015807  \n",
       "polar_dff                    0.050648  \n",
       "openkiwi_score               1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sid.polarity_scores(eng[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Sentiment analysis\n",
    "Tense (future, past, present)\n",
    "Grammatical sanity\n",
    "possesive features (like Ludo<'s>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Do we assume english text to be accurate?\n",
    "Approx same number of rules\n",
    "English\n",
    "Variants for: Australian, Canadian, GB, New Zealand, South African, US\t2790\n",
    "German\n",
    "Variants for: Austria, Germany, Swiss\t2894\n",
    "http://wiki.languagetool.org/development-overview#toc0\n",
    "    \n",
    "preprocess by cleaning both texts of grammar.\n",
    "import string\n",
    "def preprocessing(lst):\n",
    "    \n",
    "    # Remove punctuation and lower-case\n",
    "#     res = [i[0].lower().translate(str.maketrans('', '', string.punctuation)) for i in lst]\n",
    "    # Remove stop words\n",
    "    res = [i[0] for i in lst]\n",
    "    return res\n",
    "# eng = preprocessing(src)\n",
    "# ger = preprocessing(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For downloading language check need to install java8 and configure permissions\n",
    "https://stackoverflow.com/questions/24342886/how-to-install-java-8-on-mac\n",
    "https://github.com/myint/language-check/issues/59\n",
    "https://github.com/myint/language-check/issues/31\n",
    "https://stackoverflow.com/questions/40684543/how-to-make-python-use-ca-certificates-from-mac-os-truststore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
